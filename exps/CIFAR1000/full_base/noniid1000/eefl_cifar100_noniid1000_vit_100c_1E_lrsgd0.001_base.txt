alg: eefl
policy: base
dataset: cifar100_noniid1000
model: vit
config_path: models/facebook/deit-tiny-patch16-224
ft: full
load_path: 
seed: 1117
total_num: 100
sr: 0.3
suffix: exps/CIFAR1000/full_base/noniid1000
device: 3
rnd: 10
bs: 32
epoch: 1
lr: 0.001
gamma: 0.99
optim: sgd
valid_gap: 1
eq_ratios: (0.25, 0.25, 0.25, 0.25)
eq_depths: (3, 6, 9, 12)
multi_exit: False
toy: False
if_mode: all
cosine: False
valid_ratio: 0.2
eval_models_dir: script/0818-1e-1
eval_test: False
noise: -1
hidden_dim: -1
T: 3
wdb: <wandb.sdk.wandb_run.Run object at 0x7f594fdda8b0>
output: <_io.TextIOWrapper name='./exps/CIFAR1000/full_base/noniid1000/eefl_cifar100_noniid1000_vit_100c_1E_lrsgd0.001_base.txt' mode='a' encoding='UTF-8'>
========== Round 0 ==========
accuracy: 45.72, exits:['14.91', '41.72', '60.13', '66.11'] loss: 12.74
========== Round 1 ==========
accuracy: 56.53, exits:['30.24', '54.83', '68.25', '72.79'] loss: 7.44
========== Round 2 ==========
accuracy: 60.05, exits:['36.64', '58.82', '70.41', '74.31'] loss: 5.68
========== Round 3 ==========
accuracy: 62.19, exits:['39.88', '61.91', '71.93', '75.04'] loss: 4.75
========== Round 4 ==========
accuracy: 64.55, exits:['43.38', '64.29', '74.03', '76.50'] loss: 4.04
========== Round 5 ==========
accuracy: 64.84, exits:['45.14', '64.11', '73.92', '76.21'] loss: 3.51
========== Round 6 ==========
accuracy: 65.91, exits:['47.56', '65.36', '74.22', '76.51'] loss: 3.06
========== Round 7 ==========
accuracy: 66.96, exits:['49.67', '66.60', '74.53', '77.04'] loss: 2.67
