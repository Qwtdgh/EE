alg: eefl
policy: boosted
dataset: cifar100_noniid1000
model: vit
config_path: models/facebook/deit-tiny-patch16-224
ft: full
load_path: 
seed: 1117
total_num: 100
sr: 0.3
suffix: exps/CIFAR_1000/full_boosted/noniid1000
device: 1
rnd: 10
bs: 32
epoch: 1
lr: 0.01
gamma: 0.99
optim: sgd
valid_gap: 1
eq_ratios: (0.25, 0.25, 0.25, 0.25)
eq_depths: (3, 6, 9, 12)
multi_exit: False
toy: False
if_mode: all
cosine: False
valid_ratio: 0.2
eval_models_dir: script/0818-1e-1
eval_test: False
noise: -1
hidden_dim: -1
T: 3
ensemble_weight: 0.2
wdb: <wandb.sdk.wandb_run.Run object at 0x7fdbd69d4bb0>
output: <_io.TextIOWrapper name='./exps/CIFAR_1000/full_boosted/noniid1000/eefl_cifar100_noniid1000_vit_100c_1E_lrsgd0.01_boosted.txt' mode='a' encoding='UTF-8'>
========== Round 0 ==========
accuracy: 53.76, exits:['34.32', '51.83', '62.60', '66.30'] loss: 8.94
========== Round 1 ==========
accuracy: 59.67, exits:['41.22', '59.54', '67.62', '70.30'] loss: 5.78
========== Round 2 ==========
accuracy: 62.43, exits:['45.20', '61.98', '70.19', '72.35'] loss: 4.72
========== Round 3 ==========
accuracy: 63.14, exits:['48.00', '63.14', '69.83', '71.58'] loss: 4.01
========== Round 4 ==========
accuracy: 64.44, exits:['49.11', '65.16', '71.07', '72.40'] loss: 3.43
========== Round 5 ==========
accuracy: 63.38, exits:['49.63', '62.98', '69.44', '71.47'] loss: 2.98
========== Round 6 ==========
accuracy: 64.97, exits:['51.55', '64.96', '70.94', '72.44'] loss: 2.60
========== Round 7 ==========
accuracy: 64.48, exits:['52.37', '64.13', '69.92', '71.50'] loss: 2.28
========== Round 8 ==========
accuracy: 64.58, exits:['52.13', '64.30', '70.32', '71.58'] loss: 2.02
========== Round 9 ==========
accuracy: 64.77, exits:['52.97', '64.66', '69.86', '71.58'] loss: 1.81
==========Summary==========
max accuracy: 64.97
final accuracy: 64.67 +- 0.00
Anytime:
[51.8, 64.57, 70.91, 72.31], avg:64.8975
